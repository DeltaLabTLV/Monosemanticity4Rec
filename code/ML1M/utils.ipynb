{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxb-UtzcjhDq"
      },
      "source": [
        "## This code contains help functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-jU-KhY6LHq"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Any\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.sparse import csr_matrix\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "export_dir = os.getcwd()\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import plot\n",
        "import random\n",
        "import math\n",
        "import heapq\n",
        "from scipy.special import expit  # Sigmoid function\n",
        "import itertools\n",
        "from IPython.display import Latex, display\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "# Ignore FutureWarnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "test_flag = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rvEWZkEhWte"
      },
      "outputs": [],
      "source": [
        "pip install ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1CmF7q1h6iF"
      },
      "outputs": [],
      "source": [
        "from ipynb.fs.defs.data_processing import *\n",
        "from ipynb.fs.defs.models import *\n",
        "from ipynb.fs.defs.training import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG9CmIrv1Erl"
      },
      "source": [
        "Test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSOcYxWo1Eca"
      },
      "outputs": [],
      "source": [
        "# from data processing\n",
        "def test_set_gen(df_recommender_user_emb=df_user_mf, df_recommender_item_emb=df_item_mf):\n",
        "  test_subset_users = random.sample(list(df_recommender_user_emb.index), k=math.floor(df_recommender_user_emb.shape[0]*0.2))\n",
        "  test_subset_items = random.sample(list(df_recommender_item_emb.index), k=math.floor(df_recommender_item_emb.shape[0]*0.2))\n",
        "\n",
        "  return test_subset_users, test_subset_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuxN7L5qpalN"
      },
      "source": [
        "Load models for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTKOKHo_2Wbk"
      },
      "outputs": [],
      "source": [
        "# from model intialization- init test sets for users and items:\n",
        "test_subset_users, test_subset_items = test_set_gen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VIV2gXCiSxC"
      },
      "outputs": [],
      "source": [
        "#mf SAE\n",
        "test_flag=1\n",
        "autoencoder = Autoencoder(latent_dim, input_dim, activation=nn.ReLU(), tied=True, normalize = True)\n",
        "train_autoencoder(interaction_embeddings, dataset_items,dataset_users[test_subset_users],input_dim=dataset_users.shape[1], latent_dim=22)\n",
        "\n",
        "# NCF SAE\n",
        "sae_model = SparseAutoencoderNCF(input_dim=20, hidden_dim=22, topk=7, tie_weights=True)\n",
        "\n",
        "# MF\n",
        "mf_recommender = MatrixFactorization(ratings_matrix, pos_idx_ex_use,neg_idx_ex_use,neg_ex_hidden, neg_ex, pos_ex_num, K=22, alpha=0.05, beta=0.01, iterations=6, pop_flag = 1)\n",
        "\n",
        "# NCF\n",
        "model = NeuralCollaborativeFiltering(num_users=6039, num_items=3706,\n",
        "                                      embedding_dim=20, hidden_layers=[8, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umkpSmOBYnya"
      },
      "source": [
        "# KL loss term implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QByAgeWwkG13"
      },
      "outputs": [],
      "source": [
        "def kl_divergence_loss(latent_activations, sparsity_target=0.05, eps=1e-6):\n",
        "\n",
        "    # Calculate average activation of each latent unit and clamp to avoid exact 0 or 1\n",
        "    rho_hat = torch.clamp(torch.mean(latent_activations, dim=0), eps, 1 - eps)\n",
        "    rho = torch.tensor(sparsity_target, dtype=torch.float32, device=latent_activations.device)\n",
        "\n",
        "    # Compute the KL divergence with eps added inside the log to ensure numerical stability\n",
        "    kl_div = rho * torch.log((rho + eps) / (rho_hat + eps)) + \\\n",
        "             (1 - rho) * torch.log(((1 - rho) + eps) / ((1 - rho_hat) + eps))\n",
        "\n",
        "    return torch.sum(kl_div)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25Jg2qM2GLqw"
      },
      "outputs": [],
      "source": [
        "def LN(x: torch.Tensor, eps: float = 1e-5) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    if type(x) == np.ndarray:\n",
        "      x= torch.from_numpy(x)\n",
        "    mu = x.mean(dim=-1, keepdim=True)\n",
        "    x = x - mu\n",
        "    std = x.std(dim=-1, keepdim=True)\n",
        "    x = x / (std + eps)\n",
        "    return x, mu, std\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "        x, mu, std = LN(x)\n",
        "        return x, dict(mu=mu, std=std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pkH3EheXCrb"
      },
      "source": [
        "#Generating result table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCV_3kvmW4aT"
      },
      "outputs": [],
      "source": [
        "def table_maker_Wchoice(table_size:int, objects:list, main_data=df_movie, main_data_names=df_movie_names, pop_ranking=num_users_per_movie_sort, selected_columns:list= ['Movie ID', 'Name', 'Year', 'Genre','Pop_Percent']):\n",
        "    table = pd.DataFrame(0, index=range(table_size), columns=selected_columns)\n",
        "\n",
        "\n",
        "    for i in table.index:\n",
        "      if 'Name' in selected_columns:\n",
        "        pos_name = selected_columns.index('Name')\n",
        "        table.iloc[i,pos_name] =  main_data_names.loc[objects[i]].iloc[0][0:-6]\n",
        "      if 'Movie ID' in selected_columns:\n",
        "        pos_id = selected_columns.index('Movie ID')\n",
        "        table.iloc[i,pos_id] =  objects[i]\n",
        "      if 'Year' in selected_columns:\n",
        "        pos_year = selected_columns.index('Year')\n",
        "        table.iloc[i,pos_year] =  df_movie_names.loc[neuron_data[i]].iloc[0,][-5:-1]\n",
        "      if 'Genre' in selected_columns:\n",
        "        pos_genre = selected_columns.index('Genre')\n",
        "        table.iloc[i,pos_genre] = ', '.join(main_data.columns[(np.where(main_data.loc[objects[i]]==1)[0])].tolist())\n",
        "      if 'Pop_Percent' in selected_columns:\n",
        "        pos_pop = selected_columns.index('Pop_Percent')\n",
        "        table.iloc[i,pos_pop] = np.where(pop_ranking.index == objects[i])[0][0]\n",
        "\n",
        "\n",
        "    return table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2-mT_2ZumkZ"
      },
      "outputs": [],
      "source": [
        "def table_maker(table_size:int, objects:list, main_data=df_movie, main_data_names=df_movie_names, pop_ranking=num_users_per_movie_sort):\n",
        "    table = pd.DataFrame(0, index=range(table_size), columns=['movie', 'name', 'genres','pop rank'])\n",
        "    for i in table.index:\n",
        "      table.iloc[i,0] =  main_data.index[objects[i]]\n",
        "      table.iloc[i,1] =  main_data_names.iloc[objects[i]].iloc[0]\n",
        "      table.iloc[i,2] =  ', '.join(main_data.columns[(np.where(main_data.iloc[objects[i]]==1)[0])].tolist())\n",
        "      table.iloc[i,3] =  np.where(pop_ranking.index == main_data.index[objects[i]])[0][0]\n",
        "    return table\n",
        "\n",
        "\n",
        "\n",
        "def table_maker_new(table_size:int, objects:list, main_data=df_movie, main_data_names=df_movie_names, pop_ranking=num_users_per_movie_sort):\n",
        "    table = pd.DataFrame(0, index=range(table_size), columns=['Name', 'Movie ID', 'Genre'])\n",
        "    for i in table.index:\n",
        "      table.iloc[i,0] =  main_data_names.iloc[objects[i]].iloc[0]\n",
        "      table.iloc[i,1] =  main_data.index[objects[i]]\n",
        "      table.iloc[i,2] =  ', '.join(main_data.columns[(np.where(main_data.iloc[objects[i]]==1)[0])].tolist())\n",
        "\n",
        "    return table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErW9OirLAEr_"
      },
      "source": [
        "# Generating group of users w.r.t a certain concept:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6AsSww-71R2"
      },
      "outputs": [],
      "source": [
        "'''find the group'''\n",
        "'''list of users that watched movies of certain genre, sorted by the number of\n",
        "movies of the certain genre wrt the total number of movies ranked by the user'''\n",
        "# all_genres = ['Children\\'s','Drama', 'Action','Comedy', 'Adventure','Documentary',\n",
        "#               'Animation', 'Crime','Fantasy','Film-Noir','Mystery', 'Horror',\n",
        "#               'Musical', 'Romance','Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "\n",
        "def generate_users_test_group(group_concept, N,model_name):\n",
        "\n",
        "  'generates group of users who have cetain dominant preferences of specific concept'\n",
        "\n",
        "  concept_ids = np.where(df_movie[group_concept] == 1)\n",
        "\n",
        "  group_concept_movies_name = np.array(df_movie.iloc[concept_ids]['movie_id'])\n",
        "  rel_group_concept_movies_name = [movie for movie in group_concept_movies_name if movie in ratings_matrix.columns]\n",
        "  part_sum_for_group_concept=ratings_matrix.loc[:,list(rel_group_concept_movies_name)].sum(axis=1)/ratings_matrix.sum(axis=1)\n",
        "  argmax_user = part_sum_for_group_concept.iloc[model_name.test_subset_users_ind].nlargest(N).index # N users watched the biggest amount of 'genre' movies vs the total num of movies\n",
        "\n",
        "  # users watched most of group_concept movies, the number of group_concept movies\n",
        "  # they watched, and the number of movies they watched from all concepts\n",
        "  usersGroup=pd.DataFrame(part_sum_for_group_concept.loc[argmax_user])\n",
        "  usersGroup.columns = [f\"percentage of {group_concept} movies\"]\n",
        "\n",
        "  return usersGroup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4Urwu9vpxLK"
      },
      "source": [
        "# MF help functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7X-1RpyPVOd"
      },
      "outputs": [],
      "source": [
        "def rec_gen(movie_num, user, df_b_u_emb, df_b_i_emb, P, Q):\n",
        "\n",
        "  PQ_user = expit(df_b_u_emb.iloc[user,0] + pd.concat([df_b_i_emb, P.dot(Q.T)], axis=1).sum(axis=1))\n",
        "  top_rec_user = PQ_user.nlargest(movie_num)\n",
        "  top_rec_user_id = top_rec_user.index.tolist()\n",
        "\n",
        "  return top_rec_user_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_val(recommend_tuple_list):\n",
        "  normalized_data = [(item[0], (item[1] - min(recommend_tuple_list, key=lambda\n",
        "                      x: x[1])[1]) / (max(recommend_tuple_list, key=lambda x:\n",
        "                    x[1])[1] - min(recommend_tuple_list, key=lambda x: x[1])[1])) for item in recommend_tuple_list]\n",
        "  return normalized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le1SyoMa7T7S"
      },
      "outputs": [],
      "source": [
        "def normalize_matrix(matrix):\n",
        "    matrix = matrix.float()\n",
        "    min_val,_ = matrix.min(axis=0)\n",
        "    max_val,_ = matrix.max(axis=0)\n",
        "    normalized_matrix = (matrix - min_val) / (max_val - min_val)\n",
        "    return np.nan_to_num(normalized_matrix)\n",
        "\n",
        "#Converts sparse input to dense tensor.\n",
        "def convert_to_dense_tensor(sparse_matrix):\n",
        "    dense_matrix = np.array(sparse_matrix)\n",
        "    dense_tensor = torch.tensor(dense_matrix, dtype=torch.float32)\n",
        "    return dense_tensor\n",
        "\n",
        "# Ensures uniform input dimensions.\n",
        "def pad_or_truncate_tensor(tensor1, target_dim):\n",
        "    flattened_tensor = tensor1.reshape(tensor1.shape[0], -1)\n",
        "    if flattened_tensor.shape[1] < target_dim:\n",
        "        padded_tensor = torch.nn.functional.pad(flattened_tensor, (0, target_dim - flattened_tensor.size(1)))\n",
        "    else:\n",
        "        padded_tensor = flattened_tensor[:, :target_dim]\n",
        "    return padded_tensor\n",
        "\n",
        "# Ensures uniform input dimensions.\n",
        "def pad_or_truncate_tensor_0(tensor1, target_dim):\n",
        "    flattened_tensor = tensor1.reshape(tensor1.shape[0], -1)\n",
        "    if flattened_tensor.shape[0] < target_dim:\n",
        "        padded_tensor = torch.nn.functional.pad(flattened_tensor, (0, target_dim - flattened_tensor.size(1)))\n",
        "    else:\n",
        "        padded_tensor = flattened_tensor[:, :target_dim]\n",
        "    return padded_tensor\n",
        "\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lBknBkJ8H0"
      },
      "source": [
        "# Lists Correlation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMAB6VkAJqx4"
      },
      "outputs": [],
      "source": [
        "def rbo(list1, list2, p=0.9):\n",
        "    \"\"\"\n",
        "    Calculate Rank Biased Overlap (RBO) between two ranked lists.\n",
        "\n",
        "    Args:\n",
        "        list1 (list): The first ranked list.\n",
        "        list2 (list): The second ranked list.\n",
        "        p (float): The probability of considering ranks deeper in the list (default=0.9).\n",
        "                   Higher values give more weight to deeper ranks.\n",
        "\n",
        "    Returns:\n",
        "        float: The RBO score between the two lists.\n",
        "    \"\"\"\n",
        "    # Lengths of the two lists\n",
        "    len1, len2 = len(list1), len(list2)\n",
        "    max_depth = max(len1, len2)\n",
        "\n",
        "    # Track cumulative overlap\n",
        "    cumulative_overlap = 0\n",
        "    agreement = 0  # Overlap count at each depth\n",
        "\n",
        "    for d in range(1, max_depth + 1):\n",
        "        # Get the top-d elements from both lists\n",
        "        top_d1 = set(list1[:d])\n",
        "        top_d2 = set(list2[:d])\n",
        "\n",
        "        # Calculate overlap at depth d\n",
        "        agreement = len(top_d1.intersection(top_d2))\n",
        "\n",
        "        # Weighted contribution to RBO\n",
        "        cumulative_overlap += (p ** (d - 1)) * (agreement / d)\n",
        "\n",
        "    # RBO formula\n",
        "    rbo_score = (1 - p) * cumulative_overlap\n",
        "    return rbo_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36nVEkPhFz-Z"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import kendalltau\n",
        "\n",
        "def kendall_tau(list1, list2):\n",
        "    \"\"\"\n",
        "    Calculate Kendall Tau correlation between two ranked lists.\n",
        "\n",
        "    Args:\n",
        "        list1 (list): The first ranked list.\n",
        "        list2 (list): The second ranked list.\n",
        "\n",
        "    Returns:\n",
        "        float: Kendall Tau correlation coefficient.\n",
        "    \"\"\"\n",
        "    # Create ranking dictionaries for both lists\n",
        "    rank1 = {item: rank for rank, item in enumerate(list1, 1)}\n",
        "    rank2 = {item: rank for rank, item in enumerate(list2, 1)}\n",
        "\n",
        "    # Make a union of all elements\n",
        "    all_items = list(set(list1) | set(list2))\n",
        "\n",
        "    # Convert ranks to aligned lists (fill missing elements with default ranks)\n",
        "    aligned_rank1 = [rank1.get(item, len(list1) + 1) for item in all_items]\n",
        "    aligned_rank2 = [rank2.get(item, len(list2) + 1) for item in all_items]\n",
        "\n",
        "    # Use scipy's kendalltau for calculation\n",
        "    tau, _ = kendalltau(aligned_rank1, aligned_rank2)\n",
        "    return tau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Monosemanticity Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ms_score_new(df_cosine_sim_matrix, latents_items):\n",
        "  A = latents_items.detach().cpu().numpy()\n",
        "  scaler = MinMaxScaler()\n",
        "  A_norm = scaler.fit_transform(A)\n",
        "\n",
        "  N = A.shape[0]\n",
        "  K=30 \n",
        "\n",
        "  MS_scores_topK = {}\n",
        "\n",
        "  for k in range(latents_items.shape[1]):  # for each neuron\n",
        "      if k in range(latents_items.shape[1]):\n",
        "        a_k = A_norm[:, k]\n",
        "\n",
        "        top_k_idx = np.argsort(a_k)[-K:]\n",
        "        top_k_vals = a_k[top_k_idx]\n",
        "\n",
        "        # outer productof activation matrix\n",
        "        R_k = np.outer(top_k_vals, top_k_vals)\n",
        "        np.fill_diagonal(R_k, 0)\n",
        "\n",
        "        # similarity matrix\n",
        "        df_cosine_sim_matrix_array = df_cosine_sim_matrix.values\n",
        "        S_top_k = df_cosine_sim_matrix_array[np.ix_(top_k_idx, top_k_idx)]\n",
        "        np.fill_diagonal(S_top_k, 0)\n",
        "\n",
        "        # Calculate MS\n",
        "        denom = np.sum(R_k)\n",
        "        MS_k = np.sum(R_k * S_top_k) / denom if denom != 0 else 0\n",
        "        MS_scores_topK[k] = MS_k\n",
        "\n",
        "  return sum(MS_scores_topK.values())/latents_items.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ms_score_all_neurons(df_cosine_sim_matrix, latents_items):\n",
        "  A = latents_items.detach().cpu().numpy()\n",
        "  scaler = MinMaxScaler()\n",
        "  A_norm = scaler.fit_transform(A)\n",
        "\n",
        "  N = A.shape[0]\n",
        "  K=30 \n",
        "\n",
        "  MS_scores_topK = {}\n",
        "\n",
        "  for k in range(latents_items.shape[1]):  # for each neuron\n",
        "      if k in range(latents_items.shape[1]):\n",
        "        a_k = A_norm[:, k]\n",
        "\n",
        "        top_k_idx = np.argsort(a_k)[-K:]\n",
        "        top_k_vals = a_k[top_k_idx]\n",
        "\n",
        "        # outer productof activation matrix\n",
        "        R_k = np.outer(top_k_vals, top_k_vals)\n",
        "        np.fill_diagonal(R_k, 0)\n",
        "\n",
        "        # similarity matrix\n",
        "        df_cosine_sim_matrix_array = df_cosine_sim_matrix.values\n",
        "        S_top_k = df_cosine_sim_matrix_array[np.ix_(top_k_idx, top_k_idx)]\n",
        "        np.fill_diagonal(S_top_k, 0)\n",
        "\n",
        "        # Calculate MS\n",
        "        denom = np.sum(R_k)\n",
        "        MS_k = np.sum(R_k * S_top_k) / denom if denom != 0 else 0\n",
        "        MS_scores_topK[k] = MS_k\n",
        "\n",
        "  return MS_scores_topK.values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI6PqhmtJrTN"
      },
      "source": [
        "# Recommendations Extraction- NCF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBcayidm3l1a"
      },
      "outputs": [],
      "source": [
        "def get_top_k_recommendations(model, user_id, candidate_item_ids, K):\n",
        "    \"\"\"\n",
        "    Returns the top K recommended item IDs for a given user.\n",
        "\n",
        "    Args:\n",
        "        model: Trained NeuralCollaborativeFiltering model.\n",
        "        user_id: The user ID for which recommendations are needed.\n",
        "        candidate_item_ids: List (or tensor) of candidate item IDs.\n",
        "        K: The number of top recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        A list of the top K recommended item IDs.\n",
        "    \"\"\"\n",
        "    # Create a tensor for the user repeated for each candidate item.\n",
        "    user_tensor = torch.tensor([user_id] * len(candidate_item_ids), dtype=torch.long)\n",
        "    item_tensor = torch.tensor(candidate_item_ids, dtype=torch.long)\n",
        "\n",
        "    # Set the model to evaluation mode and disable gradient computation.\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Get predictions for all candidate items.\n",
        "        scores  = model(user_tensor, item_tensor)\n",
        "\n",
        "    sorted_indices = torch.argsort(scores, descending=True)\n",
        "\n",
        "    # Select the top K item IDs.\n",
        "    top_k_indices = sorted_indices[:K]\n",
        "    top_k_item_ids = [candidate_item_ids[i] for i in top_k_indices]\n",
        "    bottom_k_indices = sorted_indices[-K:-1]\n",
        "    top_k_item_ids = [candidate_item_ids[i] for i in top_k_indices]\n",
        "    recommendations = [(ratings_matrix.columns[top_k_item_ids[i]], round(float(scores[top_k_item_ids[i]].data),6)) for i in range(K)]\n",
        "\n",
        "    return scores, top_k_item_ids,recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvG_W597p6Ua"
      },
      "outputs": [],
      "source": [
        "def get_top_k_recommendations_flex(model, user_id, candidate_item_ids, K):\n",
        "    \"\"\"\n",
        "\n",
        "    TopK recommendation list for reconstructed users' and items'\n",
        "    latent representations.\n",
        "\n",
        "    Returns the top K recommended item IDs for a given user.\n",
        "\n",
        "    Args:\n",
        "        model: Trained NeuralCollaborativeFiltering model.\n",
        "        user_id: The user ID for which recommendations are needed.\n",
        "        candidate_item_ids: List (or tensor) of candidate item IDs.\n",
        "        K: The number of top recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        A list of the top K recommended item IDs.\n",
        "    \"\"\"\n",
        "    # Create a tensor for the user repeated for each candidate item.\n",
        "    user_tensor = torch.tensor([user_id] * len(candidate_item_ids), dtype=torch.long)\n",
        "    item_tensor = torch.tensor(candidate_item_ids, dtype=torch.long)\n",
        "\n",
        "    # Set the model to evaluation mode and disable gradient computation.\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        #-----\n",
        "        user_emb = model.user_embedding(user_tensor).detach().clone()\n",
        "        item_emb = model.item_embedding(item_tensor).detach().clone()\n",
        "        user_rec, user_encoded = sae_model(user_emb)\n",
        "        item_rec, item_encoded = sae_model(item_emb)\n",
        "        #------\n",
        "\n",
        "        x_hat = torch.cat([user_rec, item_rec], dim=-1)\n",
        "        y_hat = model.fc_layers(x_hat)  # (batch, 1)\n",
        "        scores = y_hat.squeeze().detach().clone()\n",
        "\n",
        "    # Sort candidate items based on their scores (descending order).\n",
        "    # torch.argsort returns indices that would sort the tensor.\n",
        "    sorted_indices = torch.argsort(scores, descending=True)\n",
        "\n",
        "    # Select the top K item IDs.\n",
        "    top_k_indices = sorted_indices[:K]\n",
        "    top_k_item_ids = [candidate_item_ids[i] for i in top_k_indices]\n",
        "    bottom_k_indices = sorted_indices[-K:-1]\n",
        "    top_k_item_ids = [candidate_item_ids[i] for i in top_k_indices]\n",
        "    recommendations = [(ratings_matrix.columns[top_k_item_ids[i]], round(float(scores[top_k_item_ids[i]].data),6)) for i in range(K)]\n",
        "    return scores, top_k_item_ids,recommendations\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def get_top_k_recommendations_flex_item(model, user_id, candidate_item_ids, K,item_rec_replace, item_id_replace):\n",
        "    \"\"\"\n",
        "    TopK recommendation list for reconstructed modified item's latent\n",
        "    representation & reconstructed user's latent representation.\n",
        "\n",
        "    Args:\n",
        "        model: Trained NeuralCollaborativeFiltering model.\n",
        "        user_id: The user ID for which recommendations are needed.\n",
        "        candidate_item_ids: List (or tensor) of candidate item IDs.\n",
        "        K: The number of top recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        A list of the top K recommended item IDs.\n",
        "    \"\"\"\n",
        "    # Create a tensor for the user repeated for each candidate item.\n",
        "    user_tensor = torch.tensor([user_id] * len(candidate_item_ids), dtype=torch.long)\n",
        "    item_tensor = torch.tensor(candidate_item_ids, dtype=torch.long)\n",
        "\n",
        "    # Set the model to evaluation mode and disable gradient computation.\n",
        "    model.eval()\n",
        "    sae_model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Get predictions for all candidate items.\n",
        "        #-----\n",
        "        user_emb = model.user_embedding(user_tensor).detach().clone()\n",
        "        item_emb = model.item_embedding(item_tensor).detach().clone()\n",
        "        user_rec, user_encoded = sae_model(user_emb)\n",
        "        item_rec, item_encoded = sae_model(item_emb)\n",
        "        #------\n",
        "        item_rec_replace = item_rec_replace.unsqueeze(-1)\n",
        "        item_rec[item_id_replace,:] = item_rec_replace.t()\n",
        "\n",
        "        x_hat = torch.cat([user_rec, item_rec], dim=-1)\n",
        "        y_hat = model.fc_layers(x_hat)  # (batch, 1)\n",
        "        scores = y_hat.squeeze().detach().clone()\n",
        "\n",
        "    # Sort candidate items based on their scores (descending order).\n",
        "    # torch.argsort returns indices that would sort the tensor.\n",
        "    sorted_indices = torch.argsort(scores, descending=True)\n",
        "\n",
        "    # Select the top K item IDs.\n",
        "    top_k_indices = sorted_indices[:K]\n",
        "    top_k_item_ids = [candidate_item_ids[i] for i in top_k_indices]\n",
        "    bottom_k_indices = sorted_indices[-K:-1]\n",
        "    top_k_item_ids = [candidate_item_ids[i] for i in top_k_indices]\n",
        "    recommendations = [(ratings_matrix.columns[top_k_item_ids[i]], round(float(scores[top_k_item_ids[i]].data),6)) for i in range(K)]\n",
        "    return scores, top_k_item_ids,recommendations\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "def get_top_k_recommendations_flex_user(model, user_id, candidate_item_ids, K,user_latent_replace):\n",
        "    \"\"\"\n",
        "    TopK recommendation list for reconstructed modified users's latent\n",
        "    representation & reconstructed items's latent representation.\n",
        "\n",
        "    Args:\n",
        "        model: Trained NeuralCollaborativeFiltering model.\n",
        "        user_id: The user ID for which recommendations are needed.\n",
        "        candidate_item_ids: List (or tensor) of candidate item IDs.\n",
        "        K: The number of top recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        A list of the top K recommended item IDs.\n",
        "    \"\"\"\n",
        "    # Create a tensor for the user repeated for each candidate item.\n",
        "    user_tensor = torch.tensor([user_id] * len(candidate_item_ids), dtype=torch.long)\n",
        "    item_tensor = torch.tensor(candidate_item_ids, dtype=torch.long)\n",
        "\n",
        "    # Set the model to evaluation mode and disable gradient computation.\n",
        "    model.eval()\n",
        "    sae_model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Get predictions for all candidate items.\n",
        "\n",
        "        #-----\n",
        "        user_emb_modificate = user_latent_replace.repeat(3706, 1)\n",
        "        item_emb = model.item_embedding(item_tensor).detach().clone()\n",
        "        user_rec, user_encoded = sae_model(user_emb_modificate)\n",
        "        item_rec, item_encoded = sae_model(item_emb)\n",
        "        #-----\n",
        "\n",
        "        x_hat = torch.cat([user_rec, item_rec], dim=-1)\n",
        "        y_hat = model.fc_layers(x_hat)  # (batch, 1)\n",
        "        scores = y_hat.squeeze().detach().clone()\n",
        "\n",
        "    # Sort candidate items based on their scores (descending order).\n",
        "    # torch.argsort returns indices that would sort the tensor.\n",
        "    sorted_indices = torch.argsort(scores, descending=True)\n",
        "\n",
        "    # Select the top K item IDs.\n",
        "    top_k_indices = sorted_indices[:K]\n",
        "    top_k_item_ids = [candidate_item_ids[i] for i in top_k_indices]\n",
        "    bottom_k_indices = sorted_indices[-K:-1]\n",
        "    top_k_item_ids = [candidate_item_ids[i] for i in top_k_indices]\n",
        "    recommendations = [(ratings_matrix.columns[top_k_item_ids[i]], round(float(scores[top_k_item_ids[i]].data),6)) for i in range(K)]\n",
        "    return scores, top_k_item_ids,recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRmvo_vCr5rM"
      },
      "source": [
        "## Evaluation metrics:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfvUduMpt_aH"
      },
      "source": [
        "NDCG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UQ680yVuAe_"
      },
      "outputs": [],
      "source": [
        "def ndcg_calc(k, model_type = 'MF', pos_idx_ex_hidden, model=model):\n",
        "\n",
        "  ndcg_sum = 0\n",
        "  ndcg_sum_all=[]\n",
        "  total = 0\n",
        "\n",
        "  for user_id in range(len(pos_idx_ex_hidden)):\n",
        "      hidden_items = pos_idx_ex_hidden[user_id]  # The relevant (hidden) items for the user\n",
        "      if model_type == 'MF':\n",
        "        recommendations = mf_recommender.recommend(user_id, k)\n",
        "      else:\n",
        "        recommendations = get_top_k_recommendations(model, user_id, list(range(3706)), k)[2]\n",
        "\n",
        "      # Compute DCG\n",
        "      dcg = 0\n",
        "      for rank, (item_id, score) in enumerate(recommendations):\n",
        "          if item_id in hidden_items:\n",
        "            # rank is the place of the recoommendation\n",
        "              dcg += score / np.log2(rank + 1 + 1)  # rank + 2 because rank starts from 0\n",
        "\n",
        "      # Compute IDCG (Ideal DCG)\n",
        "      idcg = sum(1 / np.log2(i + 2) for i in range(min(len(hidden_items), k)))\n",
        "\n",
        "      ndcg = dcg / idcg if idcg > 0 else 0\n",
        "      ndcg_sum += ndcg\n",
        "      ndcg_sum_all.append(ndcg)\n",
        "      total += 1\n",
        "\n",
        "  return avg_NDCG_at_k, ndcg_sum_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKGel2YvKFAc"
      },
      "source": [
        "MRR at k=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjc5iMRnwoFC"
      },
      "outputs": [],
      "source": [
        "def mmr_calc(k, model_type = 'MF', pos_idx_ex_hidden, model=model):\n",
        "\n",
        "  rr_sum = 0\n",
        "  total = 0\n",
        "\n",
        "  for user_id in range(len(pos_idx_ex_hidden)):\n",
        "    hidden_items = pos_idx_ex_hidden[user_id]\n",
        "    if model_type == 'MF':\n",
        "        recommendations = mf_recommender.recommend(user_id, k)\n",
        "    else:\n",
        "        recommendations = get_top_k_recommendations(model, user_id, list(range(3706)), k)[2]\n",
        "    used_flag = 0\n",
        "    for item_id in hidden_items:\n",
        "        for rank, (rec_item_id, _) in enumerate(recommendations):\n",
        "            if rec_item_id == item_id and used_flag==0:\n",
        "                used_flag = 1\n",
        "                rr_sum += 1 / (rank + 1)  # add 1 since the counting starts\n",
        "                                          # here from 0\n",
        "    total += 1\n",
        "  mrr_at_k = rr_sum / len(pos_idx_ex_hidden)\n",
        "\n",
        "  return mrr_at_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjKk1B4DKFAc"
      },
      "source": [
        "Hit rate at k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIsA1Oi9xRyC"
      },
      "outputs": [],
      "source": [
        "def hit_rate_calc(k, model_type = 'MF', pos_idx_ex_hidden, model=model):\n",
        "\n",
        "  hit_rate_at_k = 0\n",
        "  num_user_w_rel_item = 0\n",
        "\n",
        "  for user_id in range(len(pos_idx_ex_hidden)):\n",
        "    hidden_items = pos_idx_ex_hidden[user_id]\n",
        "    if model_type == 'MF':\n",
        "        recommendations = mf_recommender.recommend(user_id, k)\n",
        "    else:\n",
        "        recommendations = get_top_k_recommendations(model, user_id, list(range(3706)), k)[2]\n",
        "    used_flag = 0\n",
        "    for item_id in hidden_items:\n",
        "        for rank, (rec_item_id, _) in enumerate(recommendations):\n",
        "            if rec_item_id == item_id and used_flag==0:\n",
        "                used_flag = 1\n",
        "                num_user_w_rel_item += 1\n",
        "  hit_rate_at_k = num_user_w_rel_item/len(pos_idx_ex_hidden)\n",
        "\n",
        "  return hit_rate_at_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P_EFobXKFAc"
      },
      "source": [
        "Mean percentile rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE0pN5wyyGTC"
      },
      "outputs": [],
      "source": [
        "def mpr_calc(model_type = 'MF', pos_idx_ex_hidden, model=model):\n",
        "\n",
        "  mean_percentile_rank = 0\n",
        "  percentile_rank = 0\n",
        "\n",
        "  for user_id in range(len(pos_idx_ex_hidden)):\n",
        "    hidden_items = pos_idx_ex_hidden[user_id]\n",
        "    if model_type == 'MF':\n",
        "        recommendations = mf_recommender.recommend(user_id, 3706)\n",
        "    else:\n",
        "        recommendations = get_top_k_recommendations(model, user_id, list(range(3706)), 3706)[2]\n",
        "\n",
        "    rr = 0\n",
        "    for item_id in hidden_items:\n",
        "        for rank, (rec_item_id, _) in enumerate(recommendations):\n",
        "            if rec_item_id == item_id:\n",
        "                rr += (rank/3706)*100\n",
        "    percentile_rank += rr/len(hidden_items)\n",
        "  mean_percentile_rank = percentile_rank/len(pos_idx_ex_hidden)\n",
        "\n",
        "  return mean_percentile_rank"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
